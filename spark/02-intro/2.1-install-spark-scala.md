<link rel='stylesheet' href='../assets/css/main.css'/>

[<< back to main index](../README.md)

# Lab 2.1 : Up and Running With Spark

### Overview
We will be running Spark in a single node mode.

### Depends On
None

### Run time
20 mins

## STEP 0: To Instructor
Please go through this lab on 'screen' first.

## STEP 1: Login to your Spark node
Instructor will provide details


## STEP 2: Installing Spark
There is no 'install'.  Just unzip/untar and run :-)
(copy paste the following commands on terminal,  do not include $ in your commands)

```bash
    $   cd
    $   rm -rf  spark   # cleanup existing spark installation (if any)
    $   tar xvf files/spark-2.3.0-bin-hadoop2.7.tgz
    $   mv spark-2.3.0-bin-hadoop2.7   spark
```

Now we have spark installed in  `~/spark`  directory


## STEP 3: Running Spark

```bash
    $   ~/spark/sbin/start-all.sh
```

Verify Spark is running by 'jps' command
```bash
    $  jps
```

Your output may look like this..
```console
  30624 Jps
  30431 Master
  30565 Worker
```
you will see **Master** and **Worker**  processes running.
(you probably will get different values for process ids - first column )

Spark UI will be at port 8080 of the host.
In browser go to
  http://your_spark_host_address:8080
(be sure to use the 'public' ip address)

Bingo!  Now we have spark running.


## STEP 4: Exploring Spark UI
You will see a similar screen shot like this

<img src="../assets/images/1a.png" style="border: 5px solid grey ; max-width:100%;" />

To explore:
* Is Master and Worker running on the same node?

* Inspect memory & CPU available for Spark worker

* Note the Spark master URI, it will be something like
      spark://host_name:7077
    We will need this for later labs


## STEP 5: Download Spark labs & Data

### Labs
```bash
    $   cd
    $   git clone --depth 1  git@github.com:elephantscale/spark-labs.git

    # for v2 - latest
    # $  cd  ~/spark-labs
    # $  git checkout master

    # for 1.6 (old)
    # $  cd ~/spark-labs
    # $  git checkout v1.6
```
This will create a `spark-labs` directory that has all the labs.

### Data
Download the dataset
```bash
    # if  ~/data dir is missing, do the following
    # $   git clone --depth 1  git@github.com:elephantscale/datasets.git  data

    $   cd ~/data
    $   git pull
    $   cd   # back to home directory
```

**Downloading the dataset to your own machine**  
Please see [README.md data section](../README.md#data)

## Optional: Spark Sandbox
To run Spark on your laptop, we recommend the sandbox.  This Sandbox can run on Mac / Windows / Linux.

- [Download Sandbox](https://github.com/elephantscale/sandbox)
- [Tutorials](https://github.com/elephantscale/sandbox)
